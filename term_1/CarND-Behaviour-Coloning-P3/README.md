# Data Processing

Data quality is very important for this project more than the importance of amount of the data. I chose Udacity's original track 1 data and manually collect more data for the sharp turns on track one and append those entries to the original log file. The techniques used are as follow:

1. Remove zero angle row from the original driving log to make the distribution normal to prevent bias towards learning only driving straight line. Excessive zero labeled angle is a problem because in track one there are a lot of sharp turn after the bridge. The car initially always failed the first turn and drive off the road, and even if it did passed it failed the second one immediately. By equalizing the sample distribution, 4000 zero sample are removed, and surprisingly the model learns better in this case and keep the car always on track. I can say this is the most important part of the project.

2. Left and right camera images are randomly chosen and offset by 0.27 angle.  
3. Some common image augmentation idea are borrowed from others when reading online post, this includes RGB to HSV color space transformation to learn different road color and lighting condition, but as it turns out these technique are not essential for the success of driving on track one.
4. angles jittering is also a technique to generalized steering behavior. it randomly offset the angle for a given image by a small amount, which makes steering smoother.
5. images are randomly flipped so the model can learn a unseen but a similar condition.
6. images are resize to 32x32 to reduce training time.

# The Architecture of the Model

The network architecture design compact and small. The reason is that the image is resized and cropped to 32x32 so it is not necessary have deep and huge network to remember the details in the image. Typical convolutional neural network is used, which is summarized as follow:

lambda_layer (32, 32, 3) ->
convolution layer 1 (3, 3, 32) -> ELU -> MaxPooling(2, 2) ->
convolution layer 2 (3, 3, 16) -> ELU -> MaxPooling(2, 2) ->
Flattern
Dense (512) -> Dropout -> ELU ->
Dense (128) -> ELU ->
Dense (1)

Conv -> Activation -> Pool pattern is repeated three times to extract necessary features (two lines actually), and using two dense layers before the output. I also tried the model with only two convolution layers 32x3x3 and 16x3x3, which also works well with samples_per_epoch set to 20000. Subsampling is only made in pooling layers. As activation function, ELU is used to overcome "dying ReLU" problem. Using dropout in just after the first dense layer (with more weights!) was enough to prevent overfitting.

# Training

The training and validation dataset are split with 0.1 ratio. There are 5572 training samples, batch size is set to 100 and samples_per_epoch is 20000, epoch is set to 24. The reason for larger samples_per_epoch is that even though I only have 5572 original training data, since data are generated on the fly randomly by generator so that I can train the model with more unique data generated per epoch.  

The model is trained by feeding processed image generated by train_generator. The image/angle processing function can be found in augment_and_process(). The generator template is created for generating both training set and validation set. Validation and training set are randomly shuffled before used. I use Adam optimizer with default learning rate 0.0001 and mean square error for cost calculation. On training, I set the epoch to 24, and enable modelSaveCheckPoint and earlyStopping. ModelSaveCheckPoint allows me to capture and save the model parameters for the best validation accuracy. If the model already converged and can not be tuned even further, early termination can capture this information and stops the training process, which saves training time.  Since validation accuracy is the only indication of how the model performs on unseen dataset, the best parameter should be used for testing. During my training, it stops at epoch 14 and saves the best parameters for validation loss of 0.0330. Firing up my simulator and verify that the car drives smoothly without problem.

Two image samples are randomly chosen for before and after processing comparison. This can be found in image_1 and image_2. Histogram of steering angles before and after removing zero are saved as hist_before_remove.png and hist_after_remove.png. Please note that hist_before_remove.png represents the combined dataset of Udacity track one and my own collection dataset which is described in Data Processing section.
